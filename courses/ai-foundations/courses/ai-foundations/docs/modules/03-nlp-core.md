# 03 · NLP Core

**Objectives**
- Preprocess text: tokenization, stopwords, stemming/lemmatization.
- Generate embeddings (word2vec, GloVe, fastText, BERT).
- Apply transformer models for classification and sequence tasks.

**Lab (Autograded)**
- **Assignment:** “03-nlp-core” on GitHub Classroom  
- **Tasks:**
  1. Implement `clean_tokens(text)` in `src/text_ops.py`.
  2. Use `spacy` to extract named entities in `src/ner_ops.py`.
  3. Write tests that verify token counts and entity extraction.

**Quiz**
- 10 items covering tokenization, embeddings, and transformer basics.

**Rubric**
- All tests pass (70%)  
- Code quality + documentation (20%)  
- README clarity (10%)

**TalentLMS Unit Links**
- [Open the lab in GitHub Classroom](https://classroom.github.com/a/YOUR-INVITE-CODE)  
- [Take the Quiz](#)